{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5cabd391",
      "metadata": {},
      "source": [
        "# Perceptron (Supervised Learning)\n",
        "\n",
        "This notebook demonstrates a **NumPy-only Perceptron** implementation from `rice_ml` on **scikit-learn built-in datasets**:\n",
        "\n",
        "- **Binary classification:** `Breast Cancer Wisconsin (Diagnostic)` (`sklearn.datasets.load_breast_cancer`)  \n",
        "  - Samples: 569, Features: 30, Classes: malignant/benign  \n",
        "- **Multiclass classification:** `Iris` (`sklearn.datasets.load_iris`)  \n",
        "  - Samples: 150, Features: 4 (we visualize with 2), Classes: setosa/versicolor/virginica\n",
        "\n",
        "We will:\n",
        "1. Load data from `sklearn.datasets`\n",
        "2. Split into train/test using our NumPy utilities\n",
        "3. Standardize using our NumPy `standardize`\n",
        "4. Train `PerceptronClassifier`\n",
        "5. Evaluate accuracy + visualize learning (mistakes per epoch) and decision regions (2D)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0c771b6b",
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'PerceptronClassifier' from 'rice_ml.supervised_learning.perceptron' (c:\\Users\\sutt6\\OneDrive\\Desktop\\CMOR438\\CMOR438\\src\\rice_ml\\supervised_learning\\perceptron.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m add_repo_src_to_path()\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrice_ml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m standardize, train_test_split\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrice_ml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msupervised_learning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mperceptron\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PerceptronClassifier\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstandardize_with_params\u001b[39m(X, params):\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply (X - mean) / scale using params returned by standardize(..., return_params=True).\"\"\"\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'PerceptronClassifier' from 'rice_ml.supervised_learning.perceptron' (c:\\Users\\sutt6\\OneDrive\\Desktop\\CMOR438\\CMOR438\\src\\rice_ml\\supervised_learning\\perceptron.py)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def add_repo_src_to_path(max_up: int = 8) -> None:\n",
        "    cur = os.path.abspath(os.getcwd())\n",
        "    for _ in range(max_up):\n",
        "        candidate = os.path.join(cur, \"src\")\n",
        "        if os.path.isdir(os.path.join(candidate, \"rice_ml\")):\n",
        "            if candidate not in sys.path:\n",
        "                sys.path.insert(0, candidate)\n",
        "            return\n",
        "        cur = os.path.abspath(os.path.join(cur, \"..\"))\n",
        "    raise RuntimeError(\"Could not find 'src/rice_ml'. Run this notebook inside the repo, or install the package.\")\n",
        "\n",
        "add_repo_src_to_path()\n",
        "\n",
        "from rice_ml.processing.preprocessing import standardize, train_test_split\n",
        "from rice_ml.supervised_learning.perceptron import PerceptronClassifier\n",
        "\n",
        "\n",
        "def standardize_with_params(X, params):\n",
        "    \"\"\"Apply (X - mean) / scale using params returned by standardize(..., return_params=True).\"\"\"\n",
        "    mean = params[\"mean\"]\n",
        "    scale = params[\"scale\"]\n",
        "    return (X - mean) / scale\n",
        "\n",
        "\n",
        "def confusion_matrix_np(y_true, y_pred, labels=None):\n",
        "    \"\"\"Simple confusion matrix using NumPy only.\"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    if labels is None:\n",
        "        labels = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    labels = np.asarray(labels)\n",
        "    k = labels.size\n",
        "    cm = np.zeros((k, k), dtype=int)\n",
        "    for i, a in enumerate(labels):\n",
        "        for j, b in enumerate(labels):\n",
        "            cm[i, j] = int(np.sum((y_true == a) & (y_pred == b)))\n",
        "    return cm, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb7439c",
      "metadata": {},
      "source": [
        "## 1. Binary classification: Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e7660a",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "X = data[\"data\"]\n",
        "y = data[\"target\"]  # 0=malignant, 1=benign (per sklearn encoding)\n",
        "feature_names = data[\"feature_names\"]\n",
        "target_names = data[\"target_names\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"class names:\", target_names.tolist())\n",
        "print(\"class counts:\", {int(k): int(v) for k, v in zip(*np.unique(y, return_counts=True))})\n",
        "print(\"first 5 feature names:\", feature_names[:5].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b68f1983",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.25,\n",
        "    shuffle=True,\n",
        "    stratify=y,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# Standardize using TRAIN statistics only\n",
        "X_train_std, params = standardize(X_train, return_params=True)\n",
        "X_test_std = standardize_with_params(X_test, params)\n",
        "\n",
        "print(\"Train mean (approx):\", np.round(X_train_std.mean(axis=0)[:5], 6))\n",
        "print(\"Train std  (approx):\", np.round(X_train_std.std(axis=0)[:5], 6))\n",
        "print(\"Test  mean (approx):\", np.round(X_test_std.mean(axis=0)[:5], 6))\n",
        "print(\"Test  std  (approx):\", np.round(X_test_std.std(axis=0)[:5], 6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b336145",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train perceptron (binary)\n",
        "clf_bin = PerceptronClassifier(\n",
        "    max_iter=500,\n",
        "    learning_rate=1.0,\n",
        "    fit_intercept=True,\n",
        "    shuffle=True,\n",
        "    tol=0,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=0,\n",
        ").fit(X_train_std, y_train)\n",
        "\n",
        "train_acc = clf_bin.score(X_train_std, y_train)\n",
        "test_acc = clf_bin.score(X_test_std, y_test)\n",
        "\n",
        "print(\"Binary Perceptron:\")\n",
        "print(\"  n_iter_:\", clf_bin.n_iter_)\n",
        "print(\"  train acc:\", train_acc)\n",
        "print(\"  test  acc:\", test_acc)\n",
        "print(\"  final mistakes:\", int(clf_bin.mistakes_[-1]) if clf_bin.mistakes_ is not None and clf_bin.mistakes_.size else None)\n",
        "\n",
        "y_pred_test = clf_bin.predict(X_test_std)\n",
        "cm, labels = confusion_matrix_np(y_test, y_pred_test, labels=np.array([0, 1]))\n",
        "print(\"\\nConfusion matrix (test): rows=true, cols=pred, labels=[0,1]\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63fc0ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning curve: mistakes per epoch\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(clf_bin.mistakes_) + 1), clf_bin.mistakes_)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"mistakes\")\n",
        "plt.title(\"Perceptron training mistakes over epochs (Breast Cancer)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0744620f",
      "metadata": {},
      "source": [
        "### 1.1 Decision regions (2D visualization via PCA)\n",
        "\n",
        "The breast cancer dataset has 30 features, so we use **PCA to 2D** purely for visualization.  \n",
        "We train a separate Perceptron in the PCA space to draw the decision boundary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ba8862c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA to 2D for visualization (fit on TRAIN only)\n",
        "pca = PCA(n_components=2, random_state=0)\n",
        "Z_train = pca.fit_transform(X_train_std)\n",
        "Z_test  = pca.transform(X_test_std)\n",
        "\n",
        "clf_bin_2d = PerceptronClassifier(\n",
        "    max_iter=300,\n",
        "    learning_rate=1.0,\n",
        "    fit_intercept=True,\n",
        "    shuffle=True,\n",
        "    tol=0,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=0,\n",
        ").fit(Z_train, y_train)\n",
        "\n",
        "print(\"PCA(2D) Perceptron:\")\n",
        "print(\"  train acc:\", clf_bin_2d.score(Z_train, y_train))\n",
        "print(\"  test  acc:\", clf_bin_2d.score(Z_test, y_test))\n",
        "print(\"  explained variance ratio:\", np.round(pca.explained_variance_ratio_, 4).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8073d13c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot decision regions in PCA space (train set)\n",
        "z1_min, z1_max = Z_train[:, 0].min() - 0.5, Z_train[:, 0].max() + 0.5\n",
        "z2_min, z2_max = Z_train[:, 1].min() - 0.5, Z_train[:, 1].max() + 0.5\n",
        "\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(z1_min, z1_max, 300),\n",
        "    np.linspace(z2_min, z2_max, 300),\n",
        ")\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "pred_grid = clf_bin_2d.predict(grid).reshape(xx.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.contourf(xx, yy, pred_grid, alpha=0.25)\n",
        "plt.scatter(Z_train[:, 0], Z_train[:, 1], c=y_train, s=20)\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"Perceptron decision regions (Breast Cancer, PCA 2D, train)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db200f2f",
      "metadata": {},
      "source": [
        "## 2. Multiclass classification: Iris dataset\n",
        "\n",
        "We use a 2D feature subset for a clean visualization:\n",
        "- petal length (cm)\n",
        "- petal width (cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52744f6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X_iris = iris[\"data\"]\n",
        "y_iris = iris[\"target\"]\n",
        "iris_feature_names = iris[\"feature_names\"]\n",
        "iris_target_names = iris[\"target_names\"]\n",
        "\n",
        "# Use 2D features for visualization\n",
        "feat_idx = [2, 3]  # petal length, petal width\n",
        "X2 = X_iris[:, feat_idx]\n",
        "feat_names_2d = [iris_feature_names[i] for i in feat_idx]\n",
        "\n",
        "print(\"X2 shape:\", X2.shape)\n",
        "print(\"y shape:\", y_iris.shape)\n",
        "print(\"2D features:\", feat_names_2d)\n",
        "print(\"class names:\", iris_target_names.tolist())\n",
        "print(\"class counts:\", {int(k): int(v) for k, v in zip(*np.unique(y_iris, return_counts=True))})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e73a7369",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
        "    X2, y_iris,\n",
        "    test_size=0.25,\n",
        "    shuffle=True,\n",
        "    stratify=y_iris,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "X_train2_std, params2 = standardize(X_train2, return_params=True)\n",
        "X_test2_std = standardize_with_params(X_test2, params2)\n",
        "\n",
        "print(\"Train mean (approx):\", np.round(X_train2_std.mean(axis=0), 6))\n",
        "print(\"Train std  (approx):\", np.round(X_train2_std.std(axis=0), 6))\n",
        "print(\"Test  mean (approx):\", np.round(X_test2_std.mean(axis=0), 6))\n",
        "print(\"Test  std  (approx):\", np.round(X_test2_std.std(axis=0), 6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "561b42e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_multi = PerceptronClassifier(\n",
        "    max_iter=200,\n",
        "    learning_rate=1.0,\n",
        "    fit_intercept=True,\n",
        "    shuffle=True,\n",
        "    tol=0,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=0,\n",
        ").fit(X_train2_std, y_train2)\n",
        "\n",
        "train_acc2 = clf_multi.score(X_train2_std, y_train2)\n",
        "test_acc2 = clf_multi.score(X_test2_std, y_test2)\n",
        "\n",
        "print(\"Multiclass Perceptron (Iris 2D):\")\n",
        "print(\"  n_iter_:\", clf_multi.n_iter_)\n",
        "print(\"  train acc:\", train_acc2)\n",
        "print(\"  test  acc:\", test_acc2)\n",
        "\n",
        "y_pred2 = clf_multi.predict(X_test2_std)\n",
        "cm2, labels2 = confusion_matrix_np(y_test2, y_pred2, labels=np.array([0, 1, 2]))\n",
        "print(\"\\nConfusion matrix (test): rows=true, cols=pred, labels=[0,1,2]\")\n",
        "print(cm2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7be854",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decision regions for Iris (train set)\n",
        "x1_min, x1_max = X_train2_std[:, 0].min() - 0.5, X_train2_std[:, 0].max() + 0.5\n",
        "x2_min, x2_max = X_train2_std[:, 1].min() - 0.5, X_train2_std[:, 1].max() + 0.5\n",
        "\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(x1_min, x1_max, 400),\n",
        "    np.linspace(x2_min, x2_max, 400),\n",
        ")\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "pred = clf_multi.predict(grid).reshape(xx.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.contourf(xx, yy, pred, alpha=0.25)\n",
        "plt.scatter(X_train2_std[:, 0], X_train2_std[:, 1], c=y_train2, s=25)\n",
        "plt.xlabel(feat_names_2d[0] + \" (standardized)\")\n",
        "plt.ylabel(feat_names_2d[1] + \" (standardized)\")\n",
        "plt.title(\"Perceptron decision regions (Iris 2D, train)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834c4789",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning curve: mistakes per epoch (Iris)\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(clf_multi.mistakes_) + 1), clf_multi.mistakes_)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"mistakes\")\n",
        "plt.title(\"Perceptron training mistakes over epochs (Iris 2D)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466ce11a",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "- The **Perceptron** is a simple linear classifier trained via **mistake-driven updates**. It does **not** output calibrated probabilities (unlike logistic regression), but it is fast and easy to interpret.\n",
        "\n",
        "- **Breast Cancer (binary, 30D):**  \n",
        "  The model typically reaches **strong accuracy** after standardization. The “mistakes per epoch” curve usually **drops quickly and then flattens**, which is expected because this dataset is **not perfectly linearly separable**—so mistakes may not reach zero, and early stopping is helpful.\n",
        "\n",
        "- **Iris (multiclass, 2D petal features):**  \n",
        "  The model usually performs very well because these two petal features provide **near-linear separability** across classes. The decision-region plot shows **piecewise-linear boundaries** characteristic of linear classifiers.\n",
        "\n",
        "- Key takeaways:\n",
        "  - Standardization matters for stable training.\n",
        "  - Perceptron works best when classes are (approximately) **linearly separable**.\n",
        "  - When separability is limited, performance can plateau and different random shuffles can slightly change results.\n",
        "\n",
        "Next, we can implement and compare **Logistic Regression** (probabilistic linear classifier) or move to a **Multilayer Perceptron** for non-linear decision boundaries.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
